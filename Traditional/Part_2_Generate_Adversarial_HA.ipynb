{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximize the loss with no targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import advertorch\n",
    "from advertorch.attacks import GradientSignAttack\n",
    "from advertorch.attacks import LinfPGDAttack\n",
    "from advertorch.attacks import CarliniWagnerL2Attack\n",
    "\n",
    "# Need the model for which AE is generated here\n",
    "from Resnet_adaptation import new_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOMIZE\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate AEs for the second model\n",
    "PATH = './ha/best_model_CNN.pt'\n",
    "model = torch.load(PATH).to(device) if torch.cuda.is_available() else torch.load(PATH, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =4090.28, Std = 2164.09\n"
     ]
    }
   ],
   "source": [
    "# get scalers\n",
    "training_set = np.load('./data/train.npz')\n",
    "\n",
    "mean = round(training_set['x'][...,0].mean(), 2)\n",
    "std = round(training_set['x'][...,0].std(), 2)\n",
    "\n",
    "print(\"Mean ={}, Std = {}\".format(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many? Due to computational limitation only 320, max 2616\n",
    "#num_aes = 2616\n",
    "\n",
    "# randomly select 320?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape = (2609, 12, 150), Max = 11644.0\n",
      "shape = (2609, 12, 150), Max = 3.4904832978295723\n",
      "Box Constraints -1.8900692669898203,3.4904832978295723\n"
     ]
    }
   ],
   "source": [
    "# data for which the AEs are to be generated \n",
    "test_inputs = np.load('./ha/test_inputs.npy', allow_pickle = True)\n",
    "print(f'shape = {test_inputs.shape}, Max = {np.max(test_inputs)}')\n",
    "\n",
    "test_inputs = (test_inputs - mean)/std\n",
    "print(f'shape = {test_inputs.shape}, Max = {np.max(test_inputs)}')\n",
    "\n",
    "# Use the max and min values to constain the AEs in the box\n",
    "clip_min = np.min(test_inputs)\n",
    "clip_max = np.max(test_inputs)\n",
    "\n",
    "print(f'Box Constraints {clip_min},{clip_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TR_dataset_no_targets(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        input_seq = self.data_list[key]\n",
    "        return input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "adv_set = TR_dataset_no_targets(test_inputs)\n",
    "\n",
    "adv_loader = torch.utils.data.DataLoader(dataset=adv_set,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=None,\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same rmse loss fn, in PyTorch\n",
    "def loss_fun(out, tar):\n",
    "    rmse = torch.sqrt(torch.mean((out - tar)**2))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fgsm_no_target(model, loss_func, eps, adv_dataloader, cmin, cmax):\n",
    "    \n",
    "    FGSM_adv_signals =[]\n",
    "    eps_value = torch.tensor([eps], dtype = torch.float32).to(device)\n",
    "    \n",
    "    adversary = GradientSignAttack(model, \n",
    "                                   loss_fn= loss_func,\n",
    "                                   eps = eps_value, \n",
    "                                   clip_min=cmin, \n",
    "                                   clip_max=cmax, \n",
    "                                   targeted= False)\n",
    "    \n",
    "    for bi, data in enumerate(adv_dataloader):\n",
    "        data_batch = data.float().to(device)\n",
    "        adv_signal = adversary.perturb(data_batch)\n",
    "        FGSM_adv_signals.append(np.squeeze(adv_signal.cpu().numpy()))\n",
    "        \n",
    "    return FGSM_adv_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "(2609, 12, 150)\n"
     ]
    }
   ],
   "source": [
    "epsillon = [0., 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.2]\n",
    "\n",
    "print(epsillon[7])\n",
    "\n",
    "adv_fgsm = generate_fgsm_no_target(model, loss_fun, epsillon[7], adv_loader, clip_min, clip_max )\n",
    "adv_fgsm= np.array(adv_fgsm)\n",
    "\n",
    "print(adv_fgsm.shape)\n",
    "np.save('./ha/adv_fgsm.npy', adv_fgsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bim_no_target(model, loss_func, eps, adv_dataloader, cmin, cmax):\n",
    "    \n",
    "    BIM_adv_signals =[]\n",
    "    eps_value = torch.tensor([eps], dtype = torch.float32).to(device)\n",
    "    \n",
    "    adversary = LinfPGDAttack(model, \n",
    "                              loss_fn= loss_func,\n",
    "                              eps = eps_value,\n",
    "                              eps_iter=0.05, # per iteration change\n",
    "                              nb_iter=10, #num_iterations\n",
    "                              clip_min=cmin, \n",
    "                              clip_max=cmax, \n",
    "                              targeted= False)\n",
    "    \n",
    "    for bi, data in enumerate(adv_dataloader):\n",
    "        data_batch = data.float().to(device)\n",
    "        adv_signal = adversary.perturb(data_batch)\n",
    "        BIM_adv_signals.append(np.squeeze(adv_signal.cpu().numpy()))\n",
    "        \n",
    "    return BIM_adv_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "(2609, 12, 150)\n"
     ]
    }
   ],
   "source": [
    "print(epsillon[7])\n",
    "\n",
    "adv_bim = generate_bim_no_target(model, loss_fun, epsillon[7], adv_loader, clip_min, clip_max )\n",
    "adv_bim= np.array(adv_bim)\n",
    "\n",
    "print(adv_bim.shape)\n",
    "np.save('./ha/adv_bim.npy', adv_bim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common metric\n",
    "# define a common metric\n",
    "def measure_l2(one, two):\n",
    "    # Both will be 150*12 network wide snapshots\n",
    "    one = np.squeeze(np.array(one))\n",
    "    two = np.squeeze(np.array(two))\n",
    "    #print(one.shape)\n",
    "    #print(two.shape)\n",
    "    #c = one - two\n",
    "    #print(\"C\",c.shape)\n",
    "    l2 = np.sum(np.square(one-two))\n",
    "    return l2\n",
    "\n",
    "def notation(number):\n",
    "    str_num = str(number)\n",
    "    splits = str_num.split('.')\n",
    "    leng = int(len(splits[0]))-1\n",
    "    divisor = 1\n",
    "    for i in range(leng):\n",
    "        divisor = divisor*10\n",
    "    changed_num = round((number/divisor),2)\n",
    "    return changed_num, leng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11644.0 (2609, 12, 150)\n",
      "3.4904833 (2609, 12, 150)\n",
      "3.4904833 (2609, 12, 150)\n",
      "11644.0 (2609, 12, 150)\n",
      "11644.0 (2609, 12, 150)\n"
     ]
    }
   ],
   "source": [
    "originals = np.squeeze(np.load('./data/test.npz')['x'])[0:2609]\n",
    "print(np.max(originals), originals.shape)\n",
    "\n",
    "fgsm_flow = np.load('./ha/adv_fgsm.npy', allow_pickle = True)\n",
    "print(np.max(fgsm_flow), fgsm_flow.shape)\n",
    "\n",
    "bim_flow = np.load('./ha/adv_bim.npy', allow_pickle = True)\n",
    "print(np.max(bim_flow), bim_flow.shape)\n",
    "\n",
    "fgsm_flow = (fgsm_flow*std) + mean\n",
    "print(np.max(fgsm_flow), fgsm_flow.shape)\n",
    "\n",
    "bim_flow = (bim_flow*std) + mean\n",
    "print(np.max(bim_flow), bim_flow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal: shape = (2609,), max = 27942247630.585083\n",
      "FGSM: Mean = 13191997674.486603, a.k.a 1.32E10\n"
     ]
    }
   ],
   "source": [
    "# How much signal changed? common metric\n",
    "\n",
    "# change in signal\n",
    "fgsm_sig_change_collect = []\n",
    "for i in range(len(originals)):\n",
    "    sig_change = measure_l2(originals[i], fgsm_flow[i])\n",
    "    fgsm_sig_change_collect.append(sig_change)\n",
    "fgsm_sig_change_collect = np.array(fgsm_sig_change_collect)\n",
    "print(f'Signal: shape = {fgsm_sig_change_collect.shape}, max = {np.max(fgsm_sig_change_collect)}' )\n",
    "\n",
    "fgsm_mean = np.mean(fgsm_sig_change_collect)\n",
    "num_fgsm, exp_fgsm = notation(fgsm_mean)\n",
    "print(\"FGSM: Mean = {}, a.k.a {}E{}\".format(fgsm_mean,num_fgsm, exp_fgsm) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal: shape = (2609,), max = 26359225257.269608\n",
      "FGSM: Mean = 12910686260.948496, a.k.a 1.29E10\n"
     ]
    }
   ],
   "source": [
    "# change in signal\n",
    "bim_sig_change_collect = []\n",
    "for i in range(len(originals)):\n",
    "    sig_change = measure_l2(originals[i], bim_flow[i])\n",
    "    bim_sig_change_collect.append(sig_change)\n",
    "bim_sig_change_collect = np.array(bim_sig_change_collect)\n",
    "print(f'Signal: shape = {bim_sig_change_collect.shape}, max = {np.max(bim_sig_change_collect)}' )\n",
    "\n",
    "bim_mean = np.mean(bim_sig_change_collect)\n",
    "num_bim, exp_bim = notation(bim_mean)\n",
    "print(\"FGSM: Mean = {}, a.k.a {}E{}\".format(bim_mean,num_bim, exp_bim) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know preds dont change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ResNet predictions on AEs\n",
    "\n",
    "- For now, I directly move over to GC-GRNN. Not caring much about ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ResNet: Input, Corresponding AEs, Ground Truth, Prediction on input, Prediction on AE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE Error distribution on test inputs, on AEs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
