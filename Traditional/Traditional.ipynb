{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.var_model import VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import utils\n",
    "from lib.metrics import masked_rmse_np, masked_mape_np, masked_mae_np\n",
    "from lib.utils import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-18 18:31:59,758 - INFO - Log directory: ./\n"
     ]
    }
   ],
   "source": [
    "log_dir = './'\n",
    "log_level = 'INFO'\n",
    "logger = utils.get_logger(log_dir, __name__, 'info.log', level=log_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "- pass the historical data as some training set\n",
    "- let the periodicy and time period be understood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_average_new(train_df, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_average_predict(df, y_test, n_train, n_sample, period, null_val):\n",
    "    \n",
    "    y_predict = pd.DataFrame.copy(y_test)\n",
    "    \n",
    "    # performing test directly (from the end of training data to the very end)\n",
    "    for i in range(n_train, min(n_sample, n_train + period)):\n",
    "        #print(i)\n",
    "        \n",
    "        # from current to end of train with a periodicy of week\n",
    "        inds = [j for j in range(i % period, n_train, period)]\n",
    "        \n",
    "        # all the instances where...\n",
    "        historical = df.iloc[inds, :]\n",
    "        \n",
    "        # mean of past wednesdays\n",
    "        y_predict.iloc[i - n_train, :] = historical[historical != null_val].mean()\n",
    "        \n",
    "    # Copy each period.\n",
    "    for i in range(n_train + period, n_sample, period):\n",
    "        size = min(period, n_sample - i)\n",
    "        \n",
    "        start = i - n_train\n",
    "        \n",
    "        y_predict.iloc[start:start + size, :] = y_predict.iloc[start - period: start + size - period, :].values\n",
    "        \n",
    "    return y_predict, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I  want:\n",
    "- inputs, predictions, ground truths for train and test sets\n",
    "- a way to test inputs on a trained traditional model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how do I make this work with the PeMS data?\n",
    "- which is either available as downloaded files from PeMS\n",
    "- or the train test val npz files\n",
    "- I need df here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "TEST_RATIO = 0.2\n",
    "PERIOD = 7 * 24 * 12\n",
    "NULL_VALUE = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples: 13104, Total Sensors: 150\n",
      "\n",
      "Test Samples: 2621\n",
      "\n",
      "Train Samples: 10483\n"
     ]
    }
   ],
   "source": [
    "# The data is sensor_volume_150.csv\n",
    "data = pd.read_csv('./data/sensor_volume_150.csv')\n",
    "\n",
    "n_sample, n_sensor = data.shape\n",
    "print(f\"Total Samples: {n_sample}, Total Sensors: {n_sensor}\")\n",
    "\n",
    "n_test = int(round(n_sample * TEST_RATIO))\n",
    "print(f\"\\nTest Samples: {n_test}\")\n",
    "\n",
    "n_train = n_sample - n_test\n",
    "print(f\"\\nTrain Samples: {n_train}\")\n",
    "\n",
    "# Test set, 20% from behind\n",
    "y_test = data[-n_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predict means predictions, y_test means ground truths\n",
    "y_predict, y_test = historical_average_predict(data, y_test, n_train, n_sample, PERIOD, NULL_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-18 18:32:27,366 - INFO - Historical Average\n",
      "2021-03-18 18:32:27,367 - INFO - Model\tHorizon\tRMSE\tMAPE\tMAE\n",
      "2021-03-18 18:32:27,367 - INFO - HA\t0\t909.79\t27.13\t591.10\n",
      "2021-03-18 18:32:27,368 - INFO - HA\t1\t909.79\t27.13\t591.10\n",
      "2021-03-18 18:32:27,368 - INFO - HA\t2\t909.79\t27.13\t591.10\n",
      "2021-03-18 18:32:27,369 - INFO - HA\t3\t909.79\t27.13\t591.10\n",
      "2021-03-18 18:32:27,369 - INFO - HA\t4\t909.79\t27.13\t591.10\n",
      "2021-03-18 18:32:27,369 - INFO - HA\t5\t909.79\t27.13\t591.10\n",
      "2021-03-18 18:32:27,370 - INFO - HA\t6\t909.79\t27.13\t591.10\n",
      "2021-03-18 18:32:27,370 - INFO - HA\t7\t909.79\t27.13\t591.10\n",
      "2021-03-18 18:32:27,371 - INFO - HA\t8\t909.79\t27.13\t591.10\n",
      "2021-03-18 18:32:27,371 - INFO - HA\t9\t909.79\t27.13\t591.10\n",
      "2021-03-18 18:32:27,372 - INFO - HA\t10\t909.79\t27.13\t591.10\n",
      "2021-03-18 18:32:27,372 - INFO - HA\t11\t909.79\t27.13\t591.10\n"
     ]
    }
   ],
   "source": [
    "# print GCGRNN/ DCRNN metrics\n",
    "rmse = masked_rmse_np(preds=y_predict.values, labels=y_test.values, null_val=0)\n",
    "mape = masked_mape_np(preds=y_predict.values, labels=y_test.values, null_val=0)\n",
    "mae = masked_mae_np(preds=y_predict.values, labels=y_test.values, null_val=0)\n",
    "\n",
    "logger.info('Historical Average')\n",
    "logger.info('\\t'.join(['Model', 'Horizon', 'RMSE', 'MAPE', 'MAE']))\n",
    "for horizon in range(12):\n",
    "    line = 'HA\\t%d\\t%.2f\\t%.2f\\t%.2f' % (horizon, rmse, mape * 100, mae)\n",
    "    logger.info(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_predict(df, n_forwards=(1, 3), n_lags=4, test_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Multivariate time series forecasting using Vector Auto-Regressive Model.\n",
    "    :param df: pandas.DataFrame, index: time, columns: sensor id, content: data.\n",
    "    :param n_forwards: a tuple of horizons.\n",
    "    :param n_lags: the order of the VAR model.\n",
    "    :param test_ratio:\n",
    "    :return: [list of prediction in different horizon], dt_test\n",
    "    \"\"\"\n",
    "    n_sample, n_output = df.shape\n",
    "    n_test = int(round(n_sample * test_ratio))\n",
    "    n_train = n_sample - n_test\n",
    "    df_train, df_test = df[:n_train], df[n_train:]\n",
    "\n",
    "    scaler = StandardScaler(mean=df_train.values.mean(), std=df_train.values.std())\n",
    "    data = scaler.transform(df_train.values)\n",
    "    var_model = VAR(data)\n",
    "    var_result = var_model.fit(n_lags)\n",
    "    max_n_forwards = np.max(n_forwards)\n",
    "    # Do forecasting.\n",
    "    result = np.zeros(shape=(len(n_forwards), n_test, n_output))\n",
    "    start = n_train - n_lags - max_n_forwards + 1\n",
    "    for input_ind in range(start, n_sample - n_lags):\n",
    "        prediction = var_result.forecast(scaler.transform(df.values[input_ind: input_ind + n_lags]), max_n_forwards)\n",
    "        for i, n_forward in enumerate(n_forwards):\n",
    "            result_ind = input_ind - n_train + n_lags + n_forward - 1\n",
    "            if 0 <= result_ind < n_test:\n",
    "                result[i, result_ind, :] = prediction[n_forward - 1, :]\n",
    "\n",
    "    df_predicts = []\n",
    "    for i, n_forward in enumerate(n_forwards):\n",
    "        df_predict = pd.DataFrame(scaler.inverse_transform(result[i]), index=df_test.index, columns=df_test.columns)\n",
    "        df_predicts.append(df_predict)\n",
    "    return df_predicts, df_test\n",
    "\n",
    "def eval_var(traffic_reading_df, n_lags=3):\n",
    "    n_forwards = [1, 3, 6, 12]\n",
    "    y_predicts, y_test = var_predict(traffic_reading_df, n_forwards=n_forwards, n_lags=n_lags,\n",
    "                                     test_ratio=0.2)\n",
    "    logger.info('VAR (lag=%d)' % n_lags)\n",
    "    logger.info('Model\\tHorizon\\tRMSE\\tMAPE\\tMAE')\n",
    "    for i, horizon in enumerate(n_forwards):\n",
    "        rmse = masked_rmse_np(preds=y_predicts[i].values, labels=y_test.values, null_val=0)\n",
    "        mape = masked_mape_np(preds=y_predicts[i].values, labels=y_test.values, null_val=0)\n",
    "        mae = masked_mae_np(preds=y_predicts[i].values, labels=y_test.values, null_val=0)\n",
    "        line = 'VAR\\t%d\\t%.2f\\t%.2f\\t%.2f' % (horizon, rmse, mape * 100, mae)\n",
    "        logger.info(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-18 18:32:53,221 - INFO - VAR (lag=3)\n",
      "2021-03-18 18:32:53,222 - INFO - Model\tHorizon\tRMSE\tMAPE\tMAE\n",
      "2021-03-18 18:32:53,251 - INFO - VAR\t1\t373.76\t9.92\t262.43\n",
      "2021-03-18 18:32:53,280 - INFO - VAR\t3\t748.59\t22.67\t547.59\n",
      "2021-03-18 18:32:53,314 - INFO - VAR\t6\t937.20\t30.20\t690.56\n",
      "2021-03-18 18:32:53,350 - INFO - VAR\t12\t1044.11\t32.45\t771.60\n"
     ]
    }
   ],
   "source": [
    "# VAR\n",
    "eval_var(data, n_lags=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
