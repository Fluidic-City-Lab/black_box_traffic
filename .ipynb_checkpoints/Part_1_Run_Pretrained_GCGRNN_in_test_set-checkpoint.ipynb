{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.5\n",
      "Name: tensorflow\n",
      "Version: 1.8.0\n",
      "Summary: TensorFlow helps the tensors flow\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: opensource@google.com\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\b\\desktop\\direct\\env\\lib\\site-packages\n",
      "Requires: absl-py, gast, wheel, protobuf, astor, tensorboard, six, grpcio, termcolor, numpy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!python -V\n",
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the GC-GRNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\b\\desktop\\adversarial_traffic_flow\\adversarial_gc_grnn\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\b\\desktop\\adversarial_traffic_flow\\adversarial_gc_grnn\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\b\\desktop\\adversarial_traffic_flow\\adversarial_gc_grnn\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\b\\desktop\\adversarial_traffic_flow\\adversarial_gc_grnn\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\b\\desktop\\adversarial_traffic_flow\\adversarial_gc_grnn\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\b\\desktop\\adversarial_traffic_flow\\adversarial_gc_grnn\\env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import argparse\n",
    "\n",
    "import glob\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf # mind the tf version\n",
    "from lib.utils import load_graph_data\n",
    "from model.gcnn_supervisor import GCNNSupervisor # requires Tensorflow 1.8 or 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model being used for predictions is: ./best_model\\models-325.1414-29274\n"
     ]
    }
   ],
   "source": [
    "best_model_dir = './best_model/'\n",
    "name_splits = glob.glob(best_model_dir+'*.index')[0].split('.')\n",
    "model_filename = '.'+name_splits[1] + '.'+ name_splits[2]\n",
    "print(\"The model being used for predictions is:\",model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(\"Both below are required only in training:\")\n",
    "predictions_file =\"GCGRNN_volume_150.csv\"\n",
    "#print(\"The predictions at the end of this notebook will be available in :\", predictions_file)\n",
    "\n",
    "ground_truths_file = \"y_truth_GCGRNN_volume_150.csv\"\n",
    "#print(\"The ground truth of those predictions will be available in :\", ground_truths_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Configuration YAML for the GC-GRNN model\n",
    "\n",
    "configuration = {'base_dir' : 'results',\n",
    "                 'log_level':'INFO',\n",
    "                 'data':{'batch_size': 32,\n",
    "                           'dataset_dir': './data/',\n",
    "                           'graph_pkl_filename': './helper_files/adj_mat_volume.pkl',\n",
    "                           'test_batch_size': 64,\n",
    "                           'val_batch_size': 64},\n",
    "                 'model':{'cl_decay_steps': 2000,\n",
    "                           'horizon': 12,\n",
    "                           'input_dim': 1,\n",
    "                           'l1_decay': 0 ,\n",
    "                           'num_nodes': 150,\n",
    "                           'num_rnn_layers': 1,\n",
    "                           'output_dim': 1,\n",
    "                           'rnn_units': 128,\n",
    "                           'seq_len': 12,\n",
    "                           'use_curriculum_learning': True},\n",
    "                'train':{'base_lr': 0.01,\n",
    "                          'dropout': 0,\n",
    "                          'epoch': 0,\n",
    "                          'epochs': 300,\n",
    "                          'epsilon': 1.0e-3,\n",
    "                          'global_step': 0,\n",
    "                          'lr_decay_ratio': 0.1,\n",
    "                          'max_grad_norm': 5,\n",
    "                          'max_to_keep': 100,\n",
    "                          'min_learning_rate': 2.0e-06,\n",
    "                          'model_filename': model_filename,\n",
    "                          'optimizer': 'adam',\n",
    "                          'patience': 50,\n",
    "                          'steps': '[20]',\n",
    "                          'test_every_n_epochs': 1,\n",
    "                          'preds_file': predictions_file ,\n",
    "                          'groundtruth_file':ground_truths_file}\n",
    "                }\n",
    "                \n",
    "# Write YAML file\n",
    "config_file_name = './best_model/config_for_pre_trained_gcnn.yaml'\n",
    "with io.open(config_file_name, 'w', encoding='utf8') as outfile:\n",
    "    yaml.dump(configuration, outfile, default_flow_style=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper\n",
    "def run_gcnn(config_file, output_file, use_gpu = False ):\n",
    "    \n",
    "    # safely load the config yaml file\n",
    "    with open(config_file, 'r') as f:\n",
    "        try: \n",
    "            cfile = yaml.safe_load(f)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    \n",
    "    #with open(config_file) as f:\n",
    "        #cfile = yaml.load(f)\n",
    "    \n",
    "    # some GPU config settings with TF        \n",
    "    tf_config = tf.ConfigProto()\n",
    "    if use_gpu:\n",
    "        tf_config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "    tf_config.gpu_options.allow_growth = True\n",
    "    \n",
    "    # load the adjacency matrix graph pickle\n",
    "    graph_pkl_filename = cfile['data']['graph_pkl_filename']\n",
    "    _, _, adj_mx = load_graph_data(graph_pkl_filename)\n",
    "    \n",
    "    with tf.Session(config=tf_config) as sess:\n",
    "\n",
    "        # Instantiate a supervisor with adjacency matrix and config\n",
    "        supervisor = GCNNSupervisor(adj_mx=adj_mx, **cfile)\n",
    "\n",
    "        #load the best-model \n",
    "        supervisor.load(sess, cfile['train']['model_filename'])\n",
    "\n",
    "        # get model output\n",
    "        outputs = supervisor.evaluate(sess)\n",
    "\n",
    "        # save the predicsions to file\n",
    "        np.savez_compressed(output_file, **outputs)\n",
    "        print('Predictions saved as {}.'.format(output_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-14 11:39:57,473 - INFO - Log directory: results\\GCNN_DDGF_h_12_128_lr_0.01_bs_32_0314113957/\n",
      "2021-03-14 11:39:57,475 - INFO - {'adj_mx': array([[1., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'base_dir': 'results', 'data': {'batch_size': 32, 'dataset_dir': './data/', 'graph_pkl_filename': './helper_files/adj_mat_volume.pkl', 'test_batch_size': 64, 'val_batch_size': 64}, 'log_level': 'INFO', 'model': {'cl_decay_steps': 2000, 'horizon': 12, 'input_dim': 1, 'l1_decay': 0, 'num_nodes': 150, 'num_rnn_layers': 1, 'output_dim': 1, 'rnn_units': 128, 'seq_len': 12, 'use_curriculum_learning': True}, 'train': {'base_lr': 0.01, 'dropout': 0, 'epoch': 0, 'epochs': 300, 'epsilon': 0.001, 'global_step': 0, 'groundtruth_file': 'y_truth_GCGRNN_volume_150.csv', 'lr_decay_ratio': 0.1, 'max_grad_norm': 5, 'max_to_keep': 100, 'min_learning_rate': 2e-06, 'model_filename': './best_model\\\\models-325.1414-29274', 'optimizer': 'adam', 'patience': 50, 'preds_file': 'GCGRNN_volume_150.csv', 'steps': '[20]', 'test_every_n_epochs': 1}}\n",
      "2021-03-14 11:39:58,617 - INFO - ('x_train', (9157, 12, 150, 1))\n",
      "2021-03-14 11:39:58,618 - INFO - ('y_train', (9157, 12, 150, 1))\n",
      "2021-03-14 11:39:58,618 - INFO - ('x_val', (1308, 12, 150, 1))\n",
      "2021-03-14 11:39:58,618 - INFO - ('y_val', (1308, 12, 150, 1))\n",
      "2021-03-14 11:39:58,619 - INFO - ('x_test', (2616, 12, 150, 1))\n",
      "2021-03-14 11:39:58,619 - INFO - ('y_test', (2616, 12, 150, 1))\n",
      "GCNN/GCNN_SEQ/rnn/multi_rnn_cell/cell_0/gcnngru_cell/gates/adj:0\n",
      "GCNN/GCNN_SEQ/rnn/multi_rnn_cell/cell_0/gcnngru_cell/gates/weights:0\n",
      "GCNN/GCNN_SEQ/rnn/multi_rnn_cell/cell_0/gcnngru_cell/gates/biases:0\n",
      "GCNN/GCNN_SEQ/rnn/multi_rnn_cell/cell_0/gcnngru_cell/candidate/adj:0\n",
      "GCNN/GCNN_SEQ/rnn/multi_rnn_cell/cell_0/gcnngru_cell/candidate/weights:0\n",
      "GCNN/GCNN_SEQ/rnn/multi_rnn_cell/cell_0/gcnngru_cell/candidate/biases:0\n",
      "GCNN/GCNN_SEQ/rnn_decoder/multi_rnn_cell/cell_0/gcnngru_cell/gates/adj:0\n",
      "GCNN/GCNN_SEQ/rnn_decoder/multi_rnn_cell/cell_0/gcnngru_cell/gates/weights:0\n",
      "GCNN/GCNN_SEQ/rnn_decoder/multi_rnn_cell/cell_0/gcnngru_cell/gates/biases:0\n",
      "GCNN/GCNN_SEQ/rnn_decoder/multi_rnn_cell/cell_0/gcnngru_cell/candidate/adj:0\n",
      "GCNN/GCNN_SEQ/rnn_decoder/multi_rnn_cell/cell_0/gcnngru_cell/candidate/weights:0\n",
      "GCNN/GCNN_SEQ/rnn_decoder/multi_rnn_cell/cell_0/gcnngru_cell/candidate/biases:0\n",
      "GCNN/GCNN_SEQ/rnn_decoder/multi_rnn_cell/cell_0/gcnngru_cell/projection/w:0\n",
      "2021-03-14 11:40:03,544 - INFO - Total number of trainable parameters: 189968\n",
      "INFO:tensorflow:Restoring parameters from ./best_model\\models-325.1414-29274\n",
      "2021-03-14 11:40:34,288 - INFO - Horizon 01, MAE: 226.15, MAPE: 0.0849, RMSE: 336.26\n",
      "2021-03-14 11:40:34,313 - INFO - Horizon 02, MAE: 287.45, MAPE: 0.1111, RMSE: 431.21\n",
      "2021-03-14 11:40:34,337 - INFO - Horizon 03, MAE: 319.90, MAPE: 0.1269, RMSE: 484.31\n",
      "2021-03-14 11:40:34,360 - INFO - Horizon 04, MAE: 337.80, MAPE: 0.1370, RMSE: 515.64\n",
      "2021-03-14 11:40:34,383 - INFO - Horizon 05, MAE: 348.13, MAPE: 0.1451, RMSE: 535.03\n",
      "2021-03-14 11:40:34,405 - INFO - Horizon 06, MAE: 353.77, MAPE: 0.1510, RMSE: 546.85\n",
      "2021-03-14 11:40:34,428 - INFO - Horizon 07, MAE: 358.16, MAPE: 0.1550, RMSE: 555.05\n",
      "2021-03-14 11:40:34,451 - INFO - Horizon 08, MAE: 364.03, MAPE: 0.1582, RMSE: 566.44\n",
      "2021-03-14 11:40:34,474 - INFO - Horizon 09, MAE: 368.18, MAPE: 0.1592, RMSE: 578.08\n",
      "2021-03-14 11:40:34,496 - INFO - Horizon 10, MAE: 368.87, MAPE: 0.1577, RMSE: 582.79\n",
      "2021-03-14 11:40:34,519 - INFO - Horizon 11, MAE: 365.89, MAPE: 0.1549, RMSE: 579.86\n",
      "2021-03-14 11:40:34,541 - INFO - Horizon 12, MAE: 361.09, MAPE: 0.1515, RMSE: 572.57\n",
      "Predictions saved as ./best_model/best_model_output.npz.\n"
     ]
    }
   ],
   "source": [
    "output_filename = './best_model/best_model_output.npz'\n",
    "\n",
    "# If you do not have a GPU, set the use_gpu option to False\n",
    "run_gcnn(config_file_name,output_filename, use_gpu = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
